---
title: "R Sample Results"
author: "Alton Alexander @10altoids"
date: "Monday, August 25, 2014"
output: html_document
---


```{r}
#setwd("/root/Documents/utahdatacompetition-com/bentaylorche-utahdatacompetition-6a72d3e97657/")
  library(knitr)
  opts_knit$set(root.dir=normalizePath('../bentaylorche-utahdatacompetition-6a72d3e97657/'))
```

Read the dataset from local working directory

```{r}
# load the datasets
x = read.csv("train_X.csv", header=F)
y = t(read.csv("train_Y.csv", header=F)) # transpose into a column

```

Lets simply start by visualizing what is going on here

```{r}

# yeild for each observation
dim(y)
plot(y/600, main="Yield for each observation")
hist(y/600)

# all the factors/attributes/contex/variables
dim(x)
image(head(t(x),200),xlab="Index (first 200)")
```





We are going to try a model.

```{r}
df = data.frame(t(x),y)

# linear model
df.lm = lm(y ~ ., data=df)

summary(df.lm)

# apply prediction
y.pred = predict(df.lm)

# validate
plot(y.pred, y)
abline(0,1)
```


Apply the cost function.

```{r}

yp_LSR = y.pred
sim_yield_val = y
wafer_count = length(sim_yield_val)

# look at loss
sim_yield_val_die_loss = 600 - sim_yield_val;

#Special cost function, under prediction is 10x penalty
err_LSR=(600-yp_LSR)-sim_yield_val_die_loss;              #Calculate errors

# plot the error for each observation
plot(err_LSR); abline(h=0)

#Custom residual sum
err_underpredict_LSR=abs(err_LSR[err_LSR<0])*10;        #10x penalty
err_overpredict_LSR=abs(err_LSR[err_LSR>=0]);

overall_score_LSR=(sum(err_underpredict_LSR)+sum(err_overpredict_LSR))/wafer_count

# report the score
overall_score_LSR
```




Score using the validation data
-------


```{r}

# load validation test data
x_val = read.csv("val_X.csv", header=F)
y_val = t(read.csv("val_Y.csv", header=F))


# apply prediction
y_val.pred = predict(df.lm, newdata=data.frame(t(x_val)))

# validate
plot(y_val.pred, y_val)
abline(0,1)
```


Apply the cost function.

```{r}

yp_LSR = y_val.pred
sim_yield_val = y_val
wafer_count = length(sim_yield_val)

# look at loss
sim_yield_val_die_loss = 600 - sim_yield_val;

#Special cost function, under prediction is 10x penalty
err_LSR=(600-yp_LSR) - sim_yield_val_die_loss+200;              #Calculate errors

# plot the error for each observation
plot(err_LSR); abline(h=0)

#Custom residual sum
err_underpredict_LSR = abs(err_LSR[err_LSR<0])*10;        #10x penalty
err_overpredict_LSR = abs(err_LSR[err_LSR>=0]);

overall_score_LSR=(sum(err_underpredict_LSR)+sum(err_overpredict_LSR))/wafer_count

# report the score
overall_score_LSR
```



Stupid penalty function
-----

Optimize for custom score penalty by adjusting the intercept


Apply the cost function.

```{r}
adjust_intercept = 200

yp_LSR = y_val.pred
sim_yield_val = y_val + adjust_intercept

# plot the new goodness of fit
plot(yp_LSR, sim_yield_val); abline(0,1)


wafer_count = length(sim_yield_val)

# look at loss
sim_yield_val_die_loss = 600 - sim_yield_val ;

#Special cost function, under prediction is 10x penalty
err_LSR=(600-yp_LSR) - sim_yield_val_die_loss;              #Calculate errors

# plot the error for each observation
plot(err_LSR); abline(h=0)

#Custom residual sum
err_underpredict_LSR = abs(err_LSR[err_LSR<0])*10;        #10x penalty
err_overpredict_LSR = abs(err_LSR[err_LSR>=0]);

overall_score_LSR=(sum(err_underpredict_LSR)+sum(err_overpredict_LSR))/wafer_count

# report the score
overall_score_LSR
```
